{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Unsupervised_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danilinekamgue/python/blob/master/Unsupervised_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZkIlcLC50KR"
      },
      "source": [
        "# Unsupervised Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jB4u5EBr50KS"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5Mv-DBPHGAJ"
      },
      "source": [
        "**Connect Google Drive to Colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFrmhI9-G22i"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYcXr4N_HRc5"
      },
      "source": [
        "!ls /content/gdrive/MyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMtIT2FH50KX"
      },
      "source": [
        "## K-Means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1o2sphs50KY"
      },
      "source": [
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PPQ1q8t50Kc"
      },
      "source": [
        "# data from https://datatofish.com/k-means-clustering-python/\n",
        "X = np.array([\n",
        "    [25,34,22,27,33,33,31,22,35,34,67,54,57,43,50,57,59,52,65,47,49,48,35,33,44,45,38,43,51,46],\n",
        "    [79,51,53,78,59,74,73,57,69,75,51,32,40,47,53,36,35,58,59,50,25,20,14,12,20,5,29,27,8,7]\n",
        "])\n",
        "plt.scatter(X[0], X[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgGgCq__50Kh"
      },
      "source": [
        "kmeans = KMeans(n_clusters=4, init='random')\n",
        "kmeans.fit(X.transpose())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4IIh7tx50Kl"
      },
      "source": [
        "print(kmeans.labels_)\n",
        "print(kmeans.cluster_centers_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMsk2gxJ50Kq"
      },
      "source": [
        "plt.figure()\n",
        "plt.scatter(X[0], X[1], c=kmeans.labels_)\n",
        "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfDXFArS50Kv"
      },
      "source": [
        "# test with new points\n",
        "kmeans.predict(np.array([[30,70]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiqxrnxf50Kz"
      },
      "source": [
        "### Evaluating KMeans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IumgoWG50K0"
      },
      "source": [
        "kmeans.inertia_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1XqvBYq50K3"
      },
      "source": [
        "# the elbow!\n",
        "elbow = []\n",
        "n_clusters = range(1,15)\n",
        "for K in n_clusters:\n",
        "    kmeans = KMeans(n_clusters=K, init='random')\n",
        "    kmeans.fit(X.transpose())\n",
        "    elbow.append(kmeans.inertia_)\n",
        "plt.plot(n_clusters, elbow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG973nm750K7"
      },
      "source": [
        "## Autoencoders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WmQ_s_n50K8"
      },
      "source": [
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = MNIST('.data', download=True, train=True, transform=ToTensor())\n",
        "test_dataset = MNIST('.data', download=True, train=False, transform=ToTensor()) # we will never use it! Why?\n",
        "\n",
        "# filter out some labels\n",
        "idx = (train_dataset.targets==0) | (train_dataset.targets==1)  | (train_dataset.targets==2)\n",
        "train_dataset.targets = train_dataset.targets[idx]\n",
        "train_dataset.data = train_dataset.data[idx]\n",
        "\n",
        "tr_length = int(len(train_dataset) * 0.7)\n",
        "print(tr_length)\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, \n",
        "                                [tr_length, len(train_dataset)-tr_length])\n",
        "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True, drop_last=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe4b7GLw55lX"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyAGAvKI50LC"
      },
      "source": [
        "# what about using MLP to implement Autoencoder?\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "\n",
        "        super(Autoencoder, self).__init__()\n",
        "        \n",
        "        input_size = 28*28\n",
        "        self.enc1 = nn.Linear(input_size, 400)\n",
        "        self.enc2 = nn.Linear(400, 100)\n",
        "        self.enc3 = nn.Linear(100, 50)\n",
        "        self.enc = nn.Linear(50, hidden_size)\n",
        "        self.dec1 = nn.Linear(hidden_size, 50)\n",
        "        self.dec2 = nn.Linear(50, 100)\n",
        "        self.dec3 = nn.Linear(100, 400)\n",
        "        self.dec4 = nn.Linear(400, input_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.enc1(x))\n",
        "        x = torch.relu(self.enc2(x))\n",
        "        x = torch.relu(self.enc3(x))\n",
        "        self.code = self.enc(x)\n",
        "        x = torch.relu(self.code)\n",
        "        x = torch.relu(self.dec1(x))\n",
        "        x = torch.relu(self.dec2(x))\n",
        "        x = torch.relu(self.dec3(x))\n",
        "        out = torch.relu(self.dec4(x))\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6ZE3mX450LG"
      },
      "source": [
        "autoencoder = Autoencoder(2).to(device)\n",
        "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=1e-3)\n",
        "                             #weight_decay=1e-2)\n",
        "criterion = torch.nn.MSELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRGw3VFh50LJ"
      },
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "tr_loss = []\n",
        "val_loss = []\n",
        "for epoch in range(EPOCHS):\n",
        "    trl = 0.\n",
        "    for x,_ in train_loader:\n",
        "        x = x.view(x.size(0), -1).to(device)\n",
        "        optimizer.zero_grad()    \n",
        "        out = autoencoder(x)\n",
        "        loss = criterion(out, x)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        trl += loss.item()\n",
        "        \n",
        "    tr_loss.append(trl / float(len(train_loader)))    \n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for x, _ in val_loader:\n",
        "            x = x.view(x.size(0), -1).to(device)\n",
        "            out = autoencoder(x)\n",
        "            vll = criterion(out, x)\n",
        "            val_loss.append(vll.item())\n",
        "            \n",
        "    print(f'End epoch {epoch}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0sPAaYq50LN"
      },
      "source": [
        "plt.plot(range(len(tr_loss)), tr_loss, label='train')\n",
        "plt.plot(range(len(val_loss)), val_loss, label='validation')\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MB_SW9sa50LR"
      },
      "source": [
        "with torch.no_grad():\n",
        "    for i, (x, y) in enumerate(val_loader):\n",
        "        x = x.view(x.size(0), -1).to(device)    \n",
        "        autoencoder(x)\n",
        "        activations = autoencoder.code.cpu().numpy()\n",
        "        targets = y.cpu().numpy() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCYs3Lo650LU"
      },
      "source": [
        "import seaborn as sns\n",
        "from pandas import DataFrame\n",
        "\n",
        "points = DataFrame(activations, columns=['X', 'Y'])\n",
        "points['target'] = targets\n",
        "sns.lmplot(x='X', y='Y', data=points, hue='target', fit_reg=False, height=10)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}